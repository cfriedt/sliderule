{"name":"SlideRule","tagline":"Statistically accurate Java benchmarking - no strings attached","body":"![SlideRule](https://raw.githubusercontent.com/cfriedt/sliderule/master/misc/sliderule.jpg)\r\n### Welcome to SlideRule\r\nInspired by [Google's Caliper](https://code.google.com/p/caliper/), SlideRule is a similar utility for benchmarking Java code. SlideRule maintains a vague level of API compatibility with Caliper. In fact, the Google Caliper annotations were used as-is inside of SlideRule, with some slight modification, but the usage has remained the same.\r\n\r\nWatch the Caliper introduction video [on YouTube](https://www.youtube.com/watch?v=Rbx0HUCnF24).\r\n\r\nThe major differences between SlideRule and Caliper are:\r\n\r\n* SlideRule is simple to use. Caliper is less simple.\r\n* Caliper (beta) uses [Maven](http://maven.apache.org/) as its build and packaging system (plugin system, execution system...) and therefore has several dependencies, while SlideRule has exactly zero dependencies. In fact, SlideRule does not impose any build system on its users at all.\r\n* Caliper hooks instrumentation classes into the JVM which prevent it from being simply executable from a single jar file. This provides a finer grain of benchmarking. SlideRule has opted to sacrifice fine-grained measurement for simplicity.\r\n* Caliper is able to measure the memory footprint on a per-class basis. SlideRule is primarily concerned with measuring execution times.\r\n* In Caliper, the Measurement interface uses a double for value. In SlideRule, we use a PolymorphicType, which allows values to be of varying type.\r\n\r\n###Algorithm\r\nSlideRule relies on a a fairly basic algorithm, and some tried-and-true statistical tests, to approximate the execution time of Java code. Java code, in particular, is tricky to benchmark because the Java Virtual Machine (JVM) can employ a Just-In-Time (JIT) compiler that modifies code structure dynamically and translates Java bytecode into native instruction sequences. This means that benchmarking results can change drastically from one invocation to the next. It is therefore important to ensure that the JVM is given sufficient opportunity to optimize and JIT-compile executing Java code before beginning to evaluate execution time.\r\n\r\nThe algorithm can be loosely defined as follows:\r\n\r\n1. Query the JVM to determine how many iterations are required to activate the JIT for a particular method call. Call the method that many times in order to have the JVM compile and cache for future use.\r\n2. If a microbenchmark is being run, for an exponentially increasing number of repetitions, use the [Newton-Raphson](http://en.wikipedia.org/wiki/Newton%27s_method) method of finding roots, or [Newton's method](http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization) for finding minima, to determine when there is little to no change in variance from one execution time to the next. If a macrobenchmark is being run, the number of repetitions is simply 1.\r\n3. Run the microbenchmark a number of times until [Student's t-test](http://en.wikipedia.org/wiki/Student%27s_t-test) identifies the mean execution time within a 95% confidence interval. This stage assumes that the underlying distribution is [normal](http://en.wikipedia.org/wiki/Normal_distribution) - an assumption that will be validated later.\r\n4. Determine the number of trials required, using the Chi-Square approximation (see [DeGroot](http://www.stat.cmu.edu/~mark/degroot/3rdedition/)), for the experiment to be produce results accurate to within 1/5 of a standard deviation, with a 95% confidence level, under the assumption that the distribution is normal.\r\n5. Perform that many trials.\r\n6. Use the [Chi-Squared test](http://en.wikipedia.org/wiki/Chi-squared_test) to validate that the distribution does, with 95% certainty, represent data randomly sampled from a normally distributed random variable with the same mean and standard deviation.\r\n\r\n###Additional Features\r\nThe SlideRule command line accepts multiple similar benchmark classes in a single invocation. These classes are executed, in turn, one after the other. This is useful when, say, several execution times of different algorithms must be compared based on the same set of parameters.\r\n\r\nSlideRule does not upload users' results to a cloud application. Any data that a user generates is never shared.\r\n\r\n###Usage\r\n```shell\r\nUsage:\r\n java org.sliderule.runner.SlideRuleMain [options...] <benchmark_class_names>\r\n\r\nOptions:\r\n -h, --help         print this message\r\n -n, --dry-run      instead of measuring, execute a single rep for each scenario\r\n                    in-process\r\n -b, --benchmark    comma-separated list of benchmark methods to run; 'foo' is\r\n                    an alias for 'timeFoo' (default: all found in class)\r\n -m, --vm           comma-separated list of VMs to test on; possible values are\r\n                    configured in SlideRule's configuration file (default:\r\n                    whichever VM sliderule itself is running in, only)\r\n -i, --instrument   comma-separated list of measuring instruments to use; possible\r\n                    values are configured in SlideRule's configuration file\r\n                    (default: \"allocation,runtime\")\r\n -t, --max-trials   independent trials to perform per benchmark scenario.\r\n                    factor of minimum statistically significant number of trials\r\n                    for confidence of 95% within 1/5 of a standard deviation;\r\n                    a positive integer (default: 30)\r\n -l, --time-limit   maximum length of time allowed for a single trial; use 0 to allow\r\n                    trials to run indefinitely. (default: 30s)\r\n -r, --run-name     a user-friendly string used to identify the run\r\n -p, --print-config print the effective configuration that will be used by SlideRule\r\n -d, --delimiter    separator used in options that take multiple values (default: ',')\r\n -c, --config       location of SlideRule's configuration file (default:\r\n                    $HOME/.sliderule/config.properties)\r\n --directory        location of SlideRule's configuration and data directory\r\n                    (default: $HOME/.sliderule)\r\n --debug            integer debug level (default is -1, messages printed to stderr)\r\n\r\n -Dparam=val1,val2,...\r\n     Specifies the values to inject into the 'param' field of the benchmark\r\n     class; if multiple values or parameters are specified in this way, sliderule\r\n     will try all possible combinations.\r\n\r\n -CconfigProperty=value\r\n     Specifies a value for any property that could otherwise be specified in\r\n     $HOME/.sliderule/config.properties. Properties specified on the command line\r\n     will override those specified in the file.\r\n\r\nSee http://github.com/cfriedt/sliderule/sliderule/wiki/CommandLineOptions for more details.\r\n```\r\n###Example\r\nPlease see the [FactorialBenchmark](https://github.com/cfriedt/sliderule/blob/master/example/examples/FactorialBenchmark.java) for an example on creating a simple benchmark class. As SlideRule is mostly API-compatible with Caliper, users are encouraged to view [Caliper](https://code.google.com/p/caliper/) documentation as well and to report any undocumented inconsistencies as [Issues](https://github.com/cfriedt/sliderule/issues).\r\n\r\nFeel free to also benchmark Caliper's [examples](https://code.google.com/p/caliper/source/browse/#git%2Fexamples%2Fsrc%2Fmain%2Fjava%2Fexamples).\r\n\r\n###Status\r\nPlease check the [Releases](https://github.com/cfriedt/sliderule/releases) frequently.\r\n\r\n###License\r\nThis software Copyright (C) Christopher Friedt, 2015, and is made freely available under the terms of the Apache 2.0 license, just as Google Caliper was. See the file [LICENSE](https://github.com/cfriedt/sliderule/blob/master/LICENSE) for further details.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}